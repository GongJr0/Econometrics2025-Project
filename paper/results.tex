\section{Results}\label{sec:results}
\subsection{Design Matrix}\label{subsubsec:design_matrix}
First step of the design matrix creation is the identification of optimal $\{p, \ q\}$ parameters for the model.

\subsubsection{Autoregressive Order}\label{subsubsec:ar_order}
Application of ACF yielded a very common pattern of monotonically decreasing correlations, not outlining any specific lag order as superior.
Looking for more conclusive insights, PACF was applied.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{fig/acf_pacf}
    \caption{ACF and PACF plots of the dependent (target) variable.}
    \label{fig:acf_pacf}
\end{figure}

Figure~\ref{fig:acf_pacf} clearly shows the aforementioned decay in ACF\@. 
Conversely, PACF shows lag-1 is the only entry with actual partial contribution into the descriptive structure of $y$.\footnote{The first spike in both ACF and PACF refers to lag-0 (the variable itself) which is equal to 1 by definition.}
Interestingly, the small spikes around lag-20 of the PACF plot (corresponding to 20 quarters or 5 years) indicate that the COVID-19 shock still has a minor effect on the 2025 Real GDP\@.

\vspace{\baselineskip}

In any case, the visualization of the autocorrelation structure presents strong evidence towards the $p=1$ selection, which is used for the model generation in this paper.

\subsubsection{Exogenous Order}\label{subsubsec:exog_order}
The exogenous order selection process started with the visualization of the simple correlation vector $y$ and the lags of exogenous variables.

\begin{table}[ht]
\label{tab:exog_corr}
    \centering
    \begin{tabular}{ccc}
        \toprule
        $\mathbf{i_{lag}}$ & $\mathbf{corr(y, \ CPI_{t-i})}$ & $\mathbf{corr(y, \ u_{t-i})}$ \\
        \midrule
        0 & 0.989 & -0.221 \\
        1 & 0.988 & -0.255 \\
        2 & 0.988 & -0.221 \\
        3 & 0.988 & -0.190 \\
        4 & 0.988 & -0.236 \\
        5 & 0.988 & -0.205 \\
        \bottomrule
    \end{tabular}
    \caption{Pearson correlation coefficients between the dependent variable and lags of exogenous variables.}
\end{table}

Inspecting the table of coefficients, we see that $CPI$ consistently stays at a coefficient of 0.988\@. This indicates that the autoregressive process of $CPI$ is likely very strong, and related to the autoregressive process explaining $y$.
On the other hand, $u$ shows a more reasonable set of coefficients. Although coefficients of $u$ are also relatively stable, they reside in the reasonable range of $[-0.255, \ -0.190]$.
However, a lack of decay or noticeable regime changes in the matrices leaves this simple test inconclusive.
This inconclusiveness was expected, and the CCF plots of whitened variables were examined for clearer insights.

\begin{figure}[ht]
\label{fig:ccf}
    \centering
    \includegraphics[width=\textwidth]{fig/ccf}
    \caption{CCF plots of the whitened exogenous variables and the dependent variable.}
\end{figure}

Although not as clear as the PACF results, Figure~\ref{fig:ccf} carries much stronger insights into the cross-correlation structure compared to raw correlation coefficients.
$CPI$ shows several spikes above the significance bounds with notable lags being $\{0, 45, 47\}$.
For $u$, we observe that lag-0 is the only significant entry.
Based on the observations, lag-0 is the only selection that ensures significant lags of both exogenous variables are included.
Therefore, the cross-correlation analysis yields $q=0$ to be the optimal selection.\footnote{In Equation~\ref{eq:model_eq}, $q=0$ would mean not including exogenous variables. But as a lag order selection, it should be interpreted as using the current observations as regressors.}

\vspace{\baselineskip}
Using $q=0$ introduces the problem of \textbf{data leakage}, as current quarter values of exogenous variables would not be available at the time of estimation.
This results in a design choice of either using the closest available selection in time (i.e.\ lag-1) or in significance (selection of lag-45 or lag-47 for $CPI$).
Since introducing 45 or 47 more coefficients per variable would essentially guarantee overfitting, the final decision was in favor of using $q=1$.\footnote{Further regularization techniques, or using sparse lagged estimators are indeed possible but are deemed outside the scope of this paper.}

\subsubsection{ARX Equation}\label{subsubsec:arx_equation}
With the order specification finalized, we were left with an $ARX(1,\ 1)$ model.
The objective equation is as follows:
\begin{equation}
    \label{eq:arx}
    y_{t} = \beta_0 + \beta_{1} y_{t-1} + \beta_{2} CPI_{t-1} + \beta_{3} u_{t-1} + \varepsilon_{t}
\end{equation}

\noindent At this stage, all model variables were known, and rescaling was performed to standardize the data.
With a concrete design matrix, a final check of VIF between the two exogenous variables was performed to confirm the model parameters did not yield multicollinear exogenous components.
$VIF_{CPI, u}$ was found to be 1.023, indicating near-perfect orthogonality between exogenous regressors.

\subsubsection{Variable Distribution Equality}\label{subsubsec:var_analysis}
The standardized design matrix was used to conduct KS tests to confirm the equality of distributions.
For demonstration purposes, both a simple KS test, and a bootstrapped test with 1,000 iterations were performed.

\begin{figure}[ht]
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/ks}
        \caption{KS Test Matrix}
        \label{fig:ks_matrix}
    \end{minipage}\hfill
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/ks_boot}
        \caption{Bootstrapped KS Test Matrix}
        \label{fig:bootstrapped_ks_matrix}
    \end{minipage}
\end{figure}

We observe that the only difference in results between the two tests is in the $\{y_{t-1}, \ u_{t-1}\}$ pair.
Both tests use $H_0$: $F_x = F_y$ therefore failing to reject means there was not enough evidence to refute the equality of distributions.
However, it is important to note that these tests are not proof of equality, but rather an indication that the distributions are similar enough to not be statistically different.
In this paper, we proceed respect the results of the bootstrapped test (Figure~\ref{fig:bootstrapped_ks_matrix}) and assume equality of distributions for all variable pairs.

\vspace{\baselineskip}

\noindent\textbf{NOTE: } The p-values annotated in the Standard KS matrix are approximations derived by a 101-term Taylor expansion. (Expansion is ill-defined at $D = 0 $ for an even number of terms) The test results are evaluated by a comparison of statistics and are not supposed to yield concrete p-values.

\subsection{Model Fit}\label{subsubsec:model_fit}
The fit was performed using Ordinary Least Squares (OLS) on the matrix expansion of Equation~\ref{eq:arx}.


\subsection{Residual Analysis}\label{subsubsec:residual_analysis}
\dots

\subsection{Gauss\rule[0.5ex]{0.5em}{0.7pt}Markov Conditions}\label{subsubsec:gm_conditions}
\dots

\subsection{Residual Distribution}\label{subsubsec:residual_distribution}
\dots
